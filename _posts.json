{
	"posts": [
		{
			"title": "Building raex, The Technical Take",
			"slug": "vyuham-tech",
			"summary": "Quite possibly the most complex programming project I have undertaken...",
			"date": "June 14, 2021",
			"body": "<p>So, after the publication of my non-technical blog about <a href=\"https://github.com/vyuham\">Project Vyuha</a> I recieved a few requests to do a technical deepdive of the project, what it was built for and the reasons behind the decisions that we made during it's development. This is my attempt at doing exactly that. Please forgive me for any wrong opinion, I am a novice and have very little experience in the field out of this project.</p>\n<p>Let's start with the system design, as I have already mentioned, I am a student, doing my bachelors in Computer Engineering, and this is the first serious academically focused project I have worked on. This also means that I come in with little to no understanding of the state of the art for doing such stuff as distributed computing. I understand that what we need is a scheduler that know's the state of the entire system, what operations are running where, and that is why we chose to use the replicated statemachine approach to doing things. This is where our choice of the raft consensus algorithm comes into play, we chose to go with it because of it's much touted simplicity and robustness.</p>\n"
		},
		{
			"title": "Construction Ahead, Hard Hats Required",
			"slug": "vyuham",
			"summary": "As an undergrad, the last four years have been a journey of realization and final year was no less...",
			"date": "June 14, 2021",
			"body": "<p>Being in my final year of college, I wanted to build something interesting and learn a lot in that journey. We ended up doing some awesome stuff, but might have not met all our ambitious goals. This is my telling of the <a href=\"https://github.com/vyuham\">Project Vyuha</a> story, the name for which comes from the Sanskrit word for &quot;battle formation&quot;, given how the goal we set out to achieve was in the direction of learning how multiple computers can be organized like troops going to war against a single enemy. This was our way of learning distributed systems theory and for me to put into practice some really interesting learnings I had gathered from my work with the folks at the <a href=\"https://github.com/tikv\">TiKV project</a> a <a href=\"/blog/post/gsoc-2020\">bit earlier</a>.</p>\n<h3>Figures and plans</h3>\n<p>We planned to write a distributed process scheduler with <a href=\"https://raft.github.io\">raft-consensus</a>, but as of now, we seem to have failed in implementing it. We were doomed you might say, but I'd disagree. As a team, we have achieved something that I like to think our peers would truly be jealous of. We learned to work as a team, trying to build something ambitious, which everyone of us was apprehensive about not be able to ship in time. And while we were at it, we also did some stuff that truly amazed us, let me recount them here.</p>\n<div style=\"text-align: center\"><img src=\"https://raw.githubusercontent.com/vyuham/raex/main/docs/project_design.svg\" alt=\"project system design\" style=\"width: 100%\" /></div><h3>Raft Consensus</h3>\n<p>Having read about raft, I wanted to try implementing an idea that had popped into mind. We were at the start of the year of our undergrad program, and as final year students do, we were supposed to submit a project by the end of the year. As I was out of ideas for more interesting stuff and it only seemed to be becoming the more sensible one to work on, we chose to combine our interests in some random ways, to do something that we'd like to write home about. We were at home ofcourse, this is during the pandemic, what I mean to say is that we were trying to go out with a bang, but I digress. The idea came to take shape at one of initial brainstorming sessions as follows. We had no guidance outside our own research, so any misconceptions are our own, or of random people on the internet.</p>\n<p>We were also pretty much doing more design at this stage than coding, and we probably started that stage of development really late. As is common in college, most of us had a hard time dealing with procrastination, and we still do, maybe we'd be world's ahead without it, but then wouldn't everyone? Here is a prictorial representation of what we meant to implement with raft-consensus.</p>\n<div style=\"text-align: center\"><img src=\"https://raw.githubusercontent.com/vyuham/raft-scheduler/main/docs/scheduler.svg\" alt=\"raft scheduler\" style=\"width: 100%\" /></div><p>Whatever, we had a fun time planning and I got to do some really cool diagrams. We were heading to the implementation stage, slowly, but surely. We tried to start out with making something in python, and for reasons that we still don't know, we didn't find it right for what we were trying to do. We were faced with a choice, I feel like this needs some explanation, so here goes.</p>\n<h3>Rust? Maybe let's not...</h3>\n<p>So this is a recurring theme, I was insistent we build our project with <a href=\"https://rust-lang.org\">rust-lang</a> and I like to think we had some really big achievements because of this. Could we have achieved better results with &quot;language X&quot;? Maybe, but then no one can be sure. I have to announce my clear bias here, I am probably in love with the language, and I sure do love the community that comes with it. I am not the best programmer, but rust has made me much better as one and I find myself thinking in terms of systems more often now, about the inputs and the flows and the outputs, because of it. Rust has been just a breeze to work with, and I think my team would bear testimony.</p>\n<p>Though there was some initial apprehensions, it's not always that you consider shifting the way you think about programming, we hit the ground running. Around September, I started work on a distributed memory store module - <a href=\"https://vyuham.github.io/dstore\">dstore</a> - to emulate the way <a href=\"https://lsds.doc.ic.ac.uk/projects/faasm\">FAASM</a>, a project we were exposed to through their <a href=\"https://lsds.doc.ic.ac.uk/sites/default/files/faasm-atc20.pdf\">USENIX presentation</a>, does memory access and placement.</p>\n<h3>Async Hell() -&gt; Future&lt;Proof&gt; // Not real code :P</h3>\n<p>Working on the dstore componenet was really just reading up on a lot of stuff that was new to me. I had never written or thought about async code and hence it posed a challenge, but while there were <a href=\"https://github.com/vyuham/dstore/commit/b49ab40b223aaea4f3449106323be1df0152457b\">a few bugs</a> <a href=\"https://github.com/vyuham/dstore/commit/1fc1890c357e25b628a479a67c98ebd11a9fc0ea\">in the code</a>, we were able to fix them in decent time. Another challenge I faced was learning about RPCs, pursuing gRPC made it easier, and I would surely owe a lot of thanks to the people who built <a href=\"https://docs.rs/tonic/\">Tonic</a> and <a href=\"https://tokio.rs\">Tokio</a>, for they made it a literal walk in the park for us. I also have a lot of praise for the folks who wrote up all the wonderful documentation, the <a href=\"https://tokio.rs/tokio/tutorial\">Tokio tutorial</a> will alway remain a turning point in my journey as a developer.</p>\n<p>My understanding of how systems work and how large projects get built changed a lot in the course of this project. We were setting up con-calls to decide on deadlines we'd set to deliver our part, 2 hour long streams for pair programming and most importantly some really deep and thoughtful brainstorming sessions to figure out what we were doing wrong. And one result from this exercise was <a href=\"https://github.com/vyuham/rtrcrs\">rtrcs</a>, a ray-tracer we built in a few weeks, by reading the book <a href=\"https://raytracing.github.io/books/RayTracingInOneWeekend.html\">Ray Tracing in One Weekend</a> by Peter Shirley.</p>\n<h3>Building rtrcrs and teaching Rust</h3>\n<p>Both my teammates <a href=\"https://github.com/Firebreath1001\">Jerry</a> and <a href=\"https://github.com/bkp31415\">Bharath</a>, having had very little prior exposure to code at the systems level, took little to no time getting into tune with using the sample C++ code and their understanding of the book, to write the rust code for this component. I had to step in only <a href=\"https://github.com/vyuham/rtrcrs/commits/parallelize\">once in a weeks or so</a> to help them with the complex stuff, but this experience has changed how I percieved rust being complex and intimidating for beginners and I think we need to review that notion and put it to rest.</p>\n<p>I just find it amusing, how we ended up in a place much closer to where we were heading than we earlier thought possible. Now with a few days left for the final submissions, I am considering cheating on rust-lang to write some golang :P. Maybe an FFI bridge between the two would be the answer, anything that could just help to bring this project to completion and to put the beast to sleep would be fine. Till then... Keep safe, keep dreaming :D</p>\n"
		},
		{
			"title": "How I moved OpenSalve from using Virtualenv to Pipenv",
			"slug": "opensalve-pipenv",
			"summary": "Not being able to make things happen at the first try, I was frustrated with virtualenv...",
			"date": "January 3, 2019",
			"feature-image": "/move-pipenv-opensalve.png",
			"body": "<p>This semester in college, we had a Social Problems Solving Hackathon -<a href=\"http://hackfortomorrow.excelmec.org\">HackForTomorrow</a>- in which my team was contesting within the topic category of \"Disaster Management\". We were pushed by the emotion of fear brewing among the people of our locality towards what eventually turned out to be a horrendous disaster. Though we couldn\"t get it all together till after the event, we sure did get into the final stages of the parent competition a Social initiative of the College fest by the name of <a href=\"http://ibeto.excelmec.org\">iBeTo</a> with our project <a href=\"https://github.com/subins2000/OpenSalve\">OpenSalve</a>.</p><p><pre><code>&lt;img src=&quot;/assets/move-pipenv-opensalve.png&quot; style=&quot;width: 100em&quot; alt=&quot;Moving OpenSalve To Pipenv&quot; /&gt;</code></pre>\n</p><p>This though is not going to be the story of how we built the project. It is a log of how I moved the project from using a virtualenv setup to one that\"s way easier to setup as is shown in the PR <a href=\"https://github.com/subins2000/OpenSalve/pull/9\"><strong>subins2000/OpenSalve#9</strong>: virtualenv ~> pipenv and other minor changes</a>. In addition, now out project also adheres to most standards set by <a href=\"https://python.org\">Python.org</a>!</p><h2 id=\"reasons\">Reasons</h2><p>I had started work on the project at the behest of <a href=\"http://subinsb.com\">Subin Siby</a>(<a href=\"https://github.com/subins2000\">@subins2000</a>) for building a <strong>blockchain</strong> to validate transactions between volunteers and the govt. I did not work on the same as I had strongly disagreed on two fronts, first that I would not work on a centralized blockchain as its can instead be implemented as a database, albeit more easily, but also because I was unable to build a system to make things both decentralized and reliable.</p><p><pre><code>    &lt;div style=&quot;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&quot;&gt;</code></pre>\n<pre><code>            &lt;iframe src=&quot;//www.youtube.com/embed/GBQAKldqgZs&quot; style=&quot;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&quot; allowfullscreen title=&quot;YouTube Video&quot;&gt;&lt;/iframe&gt;</code></pre>\n<pre><code>    &lt;/div&gt;</code></pre>\n<pre><code>    &lt;strong&gt;Kenneth Reitz - Pipenv: The Future of Python Dependency Management - PyCon 2018&lt;/strong&gt;</code></pre>\n</p><p>But in parallel the setup procedure for the development of this project wasn\"t helping either. At this point the project was using <a href=\"https://virtualenvwrapper.readthedocs.io/en/latest/\"><em>virtualenvwrapper</em></a> to do most of it\"s environment setup. I agree, it is a great tool, and as such <em>Virtualenv</em> is also provided by the same people as is Pip and Pipenv, but I was also sure the project would greatly benefit from the change. Pipenv as such provides the abstraction of the setup process and also allows for a shell to be setup within the environment.</p><blockquote><pre><code>    &lt;p&gt;Two targets, one tool! Who wouldn&quot;t fall for such a charming product?&lt;/p&gt;</code></pre>\n</blockquote><p>- <em>Devdutt Shenoi</em> (I know, I\"m quoting myself :P)</p><h2 id=\"changes\">Changes</h2><p>Prior to the change, the process for install was pretty complex, here is the comand one needs to execute, to get started:</p><div class=\"highlight\"><pre><code>    &lt;pre style=&quot;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&quot;&gt;</code></pre>\n<code class=\"language-bash\" data-lang=\"bash\"><p>export VIRTUALENVWRAPPER_PYTHON<span style=\"color:#f92672\">=</span>/usr/bin/python3</p>\n<p>source ~/.local/bin/virtualenvwrapper.sh <span style=\"color:#75715e\"># Better add this to .bashrc</span></p>\n<p>mkvirtualenv opensalve</p>\n<p>rm $VIRTUAL_ENV/bin/postactivate</p>\n<p>ln -s <span style=\"color:#e6db74\"></span>realpath .env/postactivate<span style=\"color:#e6db74\"></span> $VIRTUAL_ENV/bin/postactivate</p>\n</code><pre><code>    &lt;/pre&gt;</code></pre>\n</div><p>Where as now, its a bit less complicated <strong>;-;</strong></p><div class=\"highlight\"><pre><code>    &lt;pre style=&quot;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&quot;&gt;</code></pre>\n<p><code class=\"language-bash\" data-lang=\"bash\">pipenv install</code></p>\n<pre><code>    &lt;/pre&gt;</code></pre>\n</div><p>I don\"t kid you, that\"s it. Now you know why saying <code>its less complicated</code> is an understatement. XD</p><blockquote><pre><code>    &lt;p&gt;Hashes are used everywhere, always. Security. Automatically expose security vulnerabilities.&lt;/p&gt;</code></pre>\n</blockquote><p>- <a href=\"https://github.com/pypa/pipenv#pipenv-python-development-workflow-for-humans\">README.md</a></p><p>While you might be asking \"where is the process for linking the environment variables file?\", let me console you with the fact that all these variables can now be housed within the <code>.env</code> file. So in our case <em>.env</em> looks like this:</p><div class=\"highlight\"><pre><code>    &lt;pre style=&quot;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&quot;&gt;</code></pre>\n<code class=\"language-python\" data-lang=\"python\"><p>DJANGO_SECRET_KEY<span style=\"color:#f92672\">=</span><span style=\"color:#e6db74\">'key here'</span></p>\n</code><pre><code>&lt;/pre&gt;</code></pre>\n</div><p>Whereas in the past this used to be done either manually, or as is pointed out in the above code within a file <code>.env/postactivate</code> which looked like:</p><div class=\"highlight\"><pre><code>    &lt;pre style=&quot;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&quot;&gt;</code></pre>\n<p><code class=\"language-bash\" data-lang=\"bash\"><span style=\"color:#75715e\"># Generate using https://gist.github.com/ndarville/3452907#gistcomment-1172571</span></p>\n<p>export DJANGO_SECRET_KEY<span style=\"color:#f92672\">=</span><span style=\"color:#e6db74\">'key here'</span></p>\n</code><pre><code>    &lt;/pre&gt;</code></pre>\n</div><p>Even the requirements.txt file is now retired in favour of a more <strong>\"Strict\"</strong> <code>Pipfile</code> and <code>Pipfile.lock</code> combo, much like there exists within node/npm files that define dependencies and their requierments in either the <em>development</em> or <em>production</em> stages.</p><p><strong>Conclusion:</strong> Pipenv is the tool that every Python developer must learn, we finally are in the age of better code. I leave you with a quote from <strong>Jannis Leidel</strong>, <em>former pip maintainer</em>.</p><blockquote><pre><code>    &lt;dl&gt;</code></pre>\n<pre><code>            &lt;dd&gt;Pipenv is the porcelain I always wanted to build for pip. It fits my brain and mostly replaces virtualenvwrapper and manual pip calls for me. Use it.&lt;br&gt;&lt;/dd&gt;</code></pre>\n<pre><code>    &lt;/dl&gt;</code></pre>\n</blockquote><p><pre><code>&lt;a href=&quot;https://pipenv.readthedocs.io/en/latest/&quot;&gt;Pipenv.org&lt;/a&gt; • &lt;a href=&quot;https://github.com/de-sh/blog/issues/1&quot;&gt;Comments&lt;/a&gt;</code></pre>\n</p>"
		},
		{
			"title": "A Summer of Code with TiKV",
			"slug": "gsoc-2020",
			"summary": "A summary of achievements made through the Google Summer of Code program with CNCF on the TiKV project",
			"date": "August 25, 2020",
			"feature-image": "https//dev-to-uploads.s3.amazonaws.com/i/ipx5ny8mfukw20tlqcmp.png",
			"body": "<img src=\"/blog/images/tikv.png\" width=\"100%\"><p>The <a href=\"https://drive.google.com/file/d/1_noqqI6e2nhQ3FFz-290K0OgzB7soN7u/view?usp=sharing\">project proposal</a> I had submitted aimed to take <a href=\"https://github.com/tikv/tikv\">TiKV</a> closer to full cloud native support. A vague understanding of the project allowed me to put forward the idea of supporting cloud based data stores such as AWS S3 to the TiKV storage engine, i.e. rocksdb, by making use of the <a href=\"https://github.com/rockset/rocksdb-cloud\">rocksdb-cloud</a> library. The ideas put forward by the team at TiKV also helped to better formulate a plan that has been worked on through various PRs to the sister projects that associate with the storage component of the Database. The main issue being worked on was initiated well before the GSoC project started and can be found at <a href=\"https://github.com/tikv/tikv/issues/6506\">tikv/tikv#6506</a>.</p>\n<p>during the community boding period, <a href=\"https://github.com/yiwu-arbug\">Yi Wu(@yiwu-arbug)</a> ideated further on the project with <a href=\"https://github.com/little-wallace\">Liu Wei(@little-wallace)</a>, who compiled a <a href=\"https://docs.google.com/document/d/1rEmexICjwWe02XHWOGqNBs6zA6QpFh11d-XBt5Pvp8M/edit?usp=sharing\">document with details about the desired results from the project</a>, while I was making use of the time to go through the <a href=\"https://tikv.org/docs\">documentation</a> and do compilations, tests, etc, getting familiarized with the code as well as resulting in a few PRs to fix write-ups at <a href=\"https://github.com/tikv/tikv/pull/6740\">tikv#6740</a> and <a href=\"https://github.com/tikv/website/pull/161\">tikv/website#161</a>.</p>\n<p>I also started to maintain a <a href=\"https://github.com/users/de-sh/projects/1\">GitHub project</a> to organise the work plans and provide direction to my GSoC work, you can find a <a href=\"https://github.com/users/de-sh/projects/1#card-40733594\">list of memos(weekly reports)</a> that have been written by me to help document work done on a weekly basis as well as the sub-tasks and other achievements made over the stretch of the project timeline. In the meantime I had also updated details relating to the TiKV project on the <a href=\"http://l.cncf.io\">CNCF landscape</a> by making a PR, <a href=\"https://github.com/cncf/landscape/pull/1677\">cncf/landscape#1677</a></p>\n<img src=\"https://raw.githubusercontent.com/de-sh/tikv/side/images/tikv_cloud_native_ebs.png\" align=\"left\" height=\"600\" width=\"550\" alt=\"Diagram describing my understanding of the overall task without details prior to phase 1\"><p><em>This is a diagram that concisely depicts my understanding of how the task was to achieve cloud nativity, how different it really was from the task can be depicted in another diagram</em></p>\n<h3>Phase 1</h3>\n<p>While working on the refined proposal mentioned earlier I ended up contributing <a href=\"https://github.com/tikv/tikv/pull/8066\">tikv#8066</a>, which updated the rusoto crate and utilised a single interface for identity management, leading to clearing up a few lines of code. The merger of this PR provided me a boost, but an update from Liu alerted me to how off track I had been with respect to the proposal document. Considering Liu was busy and unable to provide the necessary guidance for me to get started in contributing to the project, it was decided that a better plan had to be put in place and thus Yi took back full charge of the project and drafted the issue <a href=\"https://github.com/tikv/rust-rocksdb/issues/514\">tikv/rust-rocksdb#514</a> which we utilised most of June-July to work on.</p>\n<p>There were a lot of firsts for me in this, including my first try at writing a <a href=\"https://github.com/tikv/rust-rocksdb/blob/master/librocksdb_sys/librocksdb_cloud_sys/CMakeLists.txt\"><code>CMakeLists.txt</code></a> and creating a CPP-rust FFI interface, which essentially contributed to <a href=\"https://github.com/tikv/rust-rocksdb/pull/517\">tikv/rust-rocksdb#517</a>. Through July the project started to catch pace as Yi helped me in figuring out how to solve issues and experiment with various methods of achieving the allotted tasks, there were a lot of new learnings from the project. The editions made to sister projects also include <a href=\"https://github.com/tikv/rocksdb/pull/181\">tikv/rocksdb#181</a> which provides a solution to the problems in compiling changes added by rust-rocksdb#517. The changes related to the #517 also includes the creation of the <a href=\"https://github.com/tikv/rocksdb/pull/181\"><code>6.4.cloud</code> branch in tikv/rocksdb</a>. Most of these PRs were merged at the end of July, closing phase 1 of the project.</p>\n<h3>Phase 2</h3>\n<p>The second stage started with Yi Wu opening <a href=\"https://github.com/tikv/tikv/issue/8367\">tikv#8367</a> to provide checkpoints for adding the newly availed rust-rocksdb <code>cloud</code> feature to tikv. I have opened a PR <a href=\"https://github.com/tikv/tikv/pull/8383\">tikv#8383</a> to solve the same and have achieved the task to a respectable point. This is where we found out that the code doesn't really build as we intended it to, issues largely with linking the cloud code with the AWS-CPP-SDK and to some extent the compilation of cloud features that merged with #517, solving which I have opened <a href=\"https://github.com/tikv/rust-rocksdb/pull/529\">rust-rocksdb#529</a> and a <a href=\"https://github.com/tikv/rocksdb/pulls?q=is%3Apr+author%3Ade-sh+fix\">few associated PRs in tikv/rocksdb</a>, but this will take a lot more work.</p>\n<h3>Phase 3</h3>\n<p>The final stage of the project had been initiated on the back of building in S3 as a storage engine for TiKV. The test phase as I'd like to refer to it is focused on providing documentation of the observable performance benchmarks for S3, achieved using the <a href=\"https://github.com/axboe/fio\">fio tool</a>, one can find the related findings as follows:</p>\n<ol>\n<li><a href=\"https://gist.github.com/de-sh/92f1ca7d50675e07ea77d726b4764ec3\">random-read performance with block_size equal to 4k, 8k, 16k, up to 1M.</a></li>\n</ol>\n<ol start=\"2\">\n<li><a href=\"https://gist.github.com/de-sh/58cfa07773cbb23baf0f2e378545d2b0\">sequential-write performance for block_size=1M , with number of concurrent jobs 1,2,4 and 8.</a></li>\n</ol>\n<h3>Pull Requests made to various TiKV repositories</h3>\n<ol>\n<li><a href=\"https://github.com/tikv/rust-rocksdb/pulls?q=is%3Apr+author%3Ade-sh\">tikv/rust-rocksdb</a></li>\n</ol>\n<ol start=\"2\">\n<li><a href=\"https://github.com/tikv/tikv/pulls?q=is%3Apr+author%3Ade-sh\">tikv/TiKV</a></li>\n</ol>\n<ol start=\"3\">\n<li><a href=\"https://github.com/tikv/rocksdb/pulls?q=is%3Apr+author%3Ade-sh\">tikv/rocksdb</a></li>\n</ol>\n<h3>Plans from here on</h3>\n<p>I plan to take the project to compilation as the hurdles we are currently facing don't seem to be insurmountable. But I also intend to get back to academics for now, I am currently a senior at college and as part of my final year project, I intend to work on the learning I have attained from this project and apply it in the multimedia field, hope to keep everyone updated on it in the coming days!</p>\n<p>If you are interested in helping out with the project and taking it forward, please consider giving the <a href=\"https://github.com/users/de-sh/projects/1\">GitHub Project</a> a look.</p>\n"
		},
		{
			"title": "Async with rust, a collection of learnings",
			"slug": "async-thoughts",
			"summary": "A collection of thoughts and links that I feel have had a disproportionate impact on my journey learning async-rust",
			"date": "October 15, 2021",
			"body": "<p>I wrote my first few lines of async rust at the end of 2020, that was the first time I was actually learning about the core principles behind async/await, while building a <a href=\"https://github.com/de-sh/kvdb/commit/30f428c5263f13f6ebc3b3303d636f0c3c178ee2\">toy database</a>. Even though I have had prior experience writing code with similar keywords in javascript and python, they didn't make much sense then, it was just what I had to write to get through implementing something in code. Having been pulled into the async world while writing network facing code, I found it to be a learning that also transfered well into college as we were learning about similar stuff in a class on Programming Paradigmns.</p>\n<p>The journey into async-rust started for me with some exposure through a well written <a href=\"https://tokio.rs/tokio/tutorial\">tutorial on the tokio project's website</a>, which introduced the why in such a way that async/await totally made sense. This piece is a recollection of material that I've used to make sense of and interpret the crazy complex world of async/await over the past year or so. Anyways, if you are new and only getting started with rust and want to learn about the basics, I'd point you to <a href=\"https://www.youtube.com/watch?v=ThjvMReOXYM\">this awesome screencast on YouTube by Jon Gjengset(@jonhoo)</a>, if you'd still like to read on and learn from my journey, it's my pleasure :D</p>\n<p>Writing a lock and load mechanism for handling shared memory between threads was interesting, even more interesting was learning about how <code>lock()</code> in <code>std</code> differed from <code>lock()</code> in <code>tokio</code>. The way in which these two handled I/O also made for an interesting comparison. How all of tokio managed well with a <code>.await</code>, which until now had to be a <code>io::Result&lt;_&gt;</code> in std.</p>\n<p>To give a brief, async-rust code looks like this:</p>\n<pre><code class=\"language-rust\"></code></pre>\n<p>async fn hello() -&gt; String {</p>\n<p>// Code that waits on some IO</p>\n<p>}</p>\n<p>fn main() {</p>\n<p>let runtime = runtime_builder();                          // Creates a runtime for async operations</p>\n<p>print!(&quot;{}&quot;, runtime.on_block(async { hello().await }));  // Calls the function from within built runtime and blocks main() till it returns</p>\n<p>}</p>\n<pre><code></code></pre>\n<p>What happens here is simple, we have an async function <code>hello()</code> running from within a runtime that blocks <code>main()</code>. Wait, so what's an async function and how is it different from the regular function? Well, they are similar in how they are written, but differ in that an async function starts with the keywords <code>async fn</code> unlike the normal <code>fn</code>, here <code>async</code> is syntactic sugar that translates down as depicted below:</p>\n<pre><code class=\"language-rust\"></code></pre>\n<p>async fn hello() -&gt; String {</p>\n<p>// Logic</p>\n<p>}</p>\n<pre><code></code></pre>\n<pre><code class=\"language-rust\"></code></pre>\n<p>fn hello() -&gt; Future&lt;Output = String&gt; {</p>\n<p>// Logic</p>\n<p>}</p>\n<pre><code></code></pre>\n<p>till the &quot;future&quot; returns, in which case the value is then printed to screen by <code>print!()</code>. There's a lot of thought that has gone into how async/await within runtimes is a lot better than callbacks that have to be handled manually(as was once the norm, <em>casually points to javascript's <code>.then()</code></em>), a debate I am not going to expand upon. Here's take where this problem is presented in a classic blog called <a href=\"https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/\">&quot;What color is your function&quot;</a>, a well articulated read if I am to recommend one, in which async functions and regular functions are called colored functions that allow one to call the other, but not vice versa and how things evolved till it got here.</p>\n<p>Another great feature of async code that I've come to use a lot is <code>select!</code>, an async construct that performs multiplexing of async tasks. It has been very helpful as far as writing concurrent, multi-threaded IO/Network heavy applications goes, a note to read about and understand this is one <a href=\"https://tokio.rs/tokio/tutorial/select\">from the tokio tutorial</a>.</p>\n<p>There's a lot more complex, but fun stuff that happens here, and a lot of this is abstracted away to make the experience a breeze for beginners, but it's still well worth the time to delve into the guts of this exciting coding paradigm. I for one, will be continuing to learn a lot, that's for sure, until the next one, farewell friends :D</p>\n"
		},
		{
			"title": "Installing pip on Linux",
			"slug": "pip-linux",
			"summary": "The right way, for I have been doing it wrong the whole time...",
			"date": "December 14, 2018",
			"feature-image": "/assets/installing-pip.png",
			"body": "<p><img src=\"/assets/installing-pip.png\" alt=\"Installing pip on Ubuntu\" style=\"width: 100em\" /></p><p>So, have you been in a situation where you are not any more new to python, building stuff is easy, but not quite up to your expectations...</p><p>Then you end up discoverng the beautiful <a href=\"https://pypi.org\">Python Package Index</a>, and you just fall in love with how easy it is to install all kinds of packages, be it Django, Flask or even TensorFlow! Well, that's exactly the situation I was in after 4 years of using python!</p><p>I have installed pip and done many wonderful things with it... That is until I found out that I was doing it all wrong.</p><p>Installing pip wiht <code>sudo apt install python3-pip</code> was, to say the least, easy. But as is with anything in <a href=\"http://t.me/BEARlySec\">InfoSec</a> not the safe or the correct way, also not how I'd prefer and adhere to now... I hope you don't make the same mistake, so I bring to you, this pretty short gist of what I have learnt from my experience with PIP, and python packages in general!</p><h2 id=\"installing-pip\">Installing pip</h2><p>The way most of my friends install pip usually goes like this...</p><div class=\"highlight\"><pre><code>&lt;pre style=&quot;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&quot;&gt;</code></pre>\n<code class=\"language-bash\" data-lang=\"bash\"><p>sudo apt install python3-pip</p>\n</code><pre><code>&lt;/pre&gt;</code></pre>\n</div><p>Yes, they all use pip3 and that's what I do too... This tutorial considers the same version. Just grow up, python2.7 is almost dead!</p><p>But why do that when there's a much simpler way to do the same?</p><div class=\"highlight\"><pre><code>&lt;pre style=&quot;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&quot;&gt;</code></pre>\n<code class=\"language-bash\" data-lang=\"bash\"><p>wget https://bootstrap.pypa.io/get-pip.py</p>\n<p>python3 get-pip.py --user</p>\n</code><pre><code>&lt;/pre&gt;</code></pre>\n</div><p>And yes, I used the <code>--user</code> flag because for most usecases, I am fed up of running pip in sudo. There's the off chance that a hacker might take my carelessness as a boon to run havoc on my machine. Believe me, even linux machines are not safe from the tyrany that is malware. What I do next is make sure that my computer notices that I have pip insatlled by adding it to the PATH environment variable.</p><div class=\"highlight\"><pre><code>&lt;pre style=&quot;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&quot;&gt;</code></pre>\n<code class=\"language-bash\" data-lang=\"bash\"><p>PATH<span style=\"color:#f92672\">=</span>$HOME/.local/bin:$PATH</p>\n</code><pre><code>&lt;/pre&gt;</code></pre>\n</div><p>You can also add the line to your .bash(/zsh/fish)rc file so that the pip command works without your having to use <code>python -m pip -</code></p><p><a href=\"https://www.reddit.com/r/Python/comments/aa7yn5/i_see_a_lot_of_people_installing_pip_in_an/\">Comments</a></p>"
		},
		{
			"title": "Awesome new Python learnings",
			"slug": "python-learnings",
			"summary": "A brief on all the awesome new stuff I am learning in the world of Python programming",
			"date": "March 8, 2019",
			"body": "<p>Of late, I have been working on a few Open Source Python projects, thus I have been exposed to a lot of new syntax and coding styles that were once pretty alien to me, all my sureties about having been an awesome Pythonista have since come crashing down. While this might seem to be a really sad realization, I'd rather say it was a pleasent learning experience and more of a surprise than a rude shock.</p><p>I am really glad that I started working on these projects, they are helping me make the kind of mental models for the purpose of writing code, that I otherwise wouldn't have been able to do in even a corporate setup. Some of these realizations are being covered here, in what I would prefer to remain, a short note.</p><h2 id=\"numerical-seperators\">Numerical Seperators</h2><p>I seriously don't know what to call these and I didn't know that they existed, yet here I am. So the thing is, I never worked with enormous numbers, I seriously am bad at dealing with big ints and the one time in my life where I did really big calculations, I used a lot of JS and the whole thing flopped, must have been just me or it was just bad timing.</p><p>Anyways, I have learnt over the last few days that within Python you can seperated numbers that are large into the \"place notation\", i.e. similar to how you write million as 1,000,000 instead of 1000000. This can be done with the seperators being underscores \"_\" defined in <a href=\"https://www.python.org/dev/peps/pep-0515/\">PEP 515</a>.</p><div class=\"highlight\"><pre><code>&lt;pre style=&quot;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&quot;&gt;</code></pre>\n<code class=\"language-python\" data-lang=\"python\"><p>M <span style=\"color:#f92672\">=</span> <span style=\"color:#ae81ff\">1</span>_000_000</p>\n<p><span style=\"color:#66d9ef\">print</span>(M) <span style=\"color:#75715e\"># Outputs ~ 1000000</span></p>\n</code><pre><code>&lt;/pre&gt;</code></pre>\n</div><h2 id=\"function-annotations\">Function Annotations</h2><p>I had thought all through my 6 years coding with Python that it was just for those who wanted to be type agnostic, with data being preferably just of a single type. But this I have since come to learn is very tough an ask, esepecially since data is of too many types to not have a caveat when storing large numbers or in storing strings that are not as large, but use very complex characters, how are we to represent the same in memory?</p><p>These issues are taken care of by the use of the Python Annotations that came to be from <a href=\"https://www.python.org/dev/peps/pep-3107/\">PEP 3107</a></p><div class=\"highlight\"><pre><code>&lt;pre style=&quot;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&quot;&gt;</code></pre>\n<p><code class=\"language-python\" data-lang=\"python\"><span style=\"color:#66d9ef\">def</span> <span style=\"color:#a6e22e\">func</span>(val:str <span style=\"color:#f92672\">=</span> <span style=\"color:#e6db74\">&quot;Hello&quot;</span>) <span style=\"color:#f92672\">-&gt;</span> str: <span style=\"color:#75715e\"># &quot;Hello&quot; being default value</span></p>\n<pre><code>&lt;span style=&quot;color:#66d9ef&quot;&gt;return&lt;/span&gt; val</code></pre>\n</code><pre><code>&lt;/pre&gt;</code></pre>\n</div><p>The main aim of this technique is to take away some of the decisions regarding data types from the interpreter and give it back to the programmer. While you can argue that there is no use to make the whole thing a standard practice, I think it was a good step nonetheless to include it.</p><h2 id=\"function-decorators\">Function Decorators</h2><p>With my knowledge of the language being extremely narrow and confused, with a wide variety of misconceptions having formed, especially about what is and what is not pythonic code, it is tough for me to judge what is the best way to solve a problem. I am a person who prefers complex, yet performant code over the easy to write code, but Python has thought me that you can have the cake and eat it too, seldom slowly. As is also pointed out in the <a href=\"https://www.python.org/dev/peps/pep-0318/\">PEP 318</a>.</p><div class=\"highlight\"><pre><code>&lt;pre style=&quot;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4&quot;&gt;</code></pre>\n<code class=\"language-python\" data-lang=\"python\"><p><span style=\"color:#a6e22e\">@callable</span>(var) <span style=\"color:#75715e\"># callable() is being called on another function, func()</span></p>\n<p><span style=\"color:#66d9ef\">def</span> <span style=\"color:#a6e22e\">func</span>(val:type) <span style=\"color:#f92672\">-&gt;</span> str:</p>\n<pre><code>&lt;span style=&quot;color:#66d9ef&quot;&gt;pass&lt;/span&gt; &lt;span style=&quot;color:#75715e&quot;&gt;# this statement does nothing&lt;/span&gt;</code></pre>\n</code><pre><code>&lt;/pre&gt;</code></pre>\n</div><h2 id=\"conclusions\">Conclusions</h2><p>There are a lot many new features in the ever-expanding arsenal of the Python developer and this helps programmers write performant code that is <strong>pythonic</strong> in nature.</p>"
		},
		{
			"title": "Building a Universal Parser, Improving Hydrus and Demo",
			"slug": "gsoc-proposal",
			"summary": "Proposal to Hydra Ecosystem(HTTP-APIs), by Devdutt Shenoi(de-sh)",
			"date": "April 5, 2019",
			"feature-image": "/assets/federated-hydrus-real-world.png",
			"body": "<h2 id=\"introduction\">Introduction</h2><p>The Hydrus server and it's associated packages as of now are at a stage where they apply most of the Hydra draft documentation framework, but the suite still needs a lot of work to make it usable in the production environment.</p><p>The proposed project is aimed at adding functionalities to hydrus and the hydra-openapi parser. As a main focus, building support for various other APIDoc specs/languages to the HydraAPI spec documentation for use by hydrus or other components of the package, adding HTTP/2 and asyncio support to Hydrus as well as making necessary changes to the core package and updating it to use the latest specs of Hydra. I would also like to contribute by adding to the general Hydra Ecosystem of packages, making updates to hydrus as pointed down below.</p><h2 id=\"project-goals\">Project Goals</h2><ul><li>The hydra-openapi-parser only supports OpenAPI 2.0 features, that needs to change as the latest version of the OAS spec(<em>v3.0</em>) is brought in with support for new features in the updated Documentation format for conversion into HydraDoc</li><li>Support can also be further extended to RAML within the parser. This has to be best achieved in a fashion that makes the parser framework agnostic.</li><li>Hydra Draft has seen some changes that have not been updated onto Hydrus, it is a goal to update hydra-python-core to implement these changes</li><li>Implementation of the HTTP/2 protocol by porting the application from flask to quart, making use of asyncio.</li><li>Building an example real-world-app implementation making use of all of the Hydra Ecosystem of packages to demonstrate its capabilities.</li></ul><h2 id=\"implementation-plans\">Implementation Plans</h2><p>Some means through which I propose to achieve my project goals include, but are not limited to:<ul>\n<li>Implement the OpenAPI-Core validator as pointed out in <a href=\"https://github.com/HTTP-APIs/hydra-openapi-parser/issues/6\">hydra-openapi-core#6</a>.</li>\n</ul>\n<p>Thus ensuring that all OAS specifications passed to the parser are validated before parsing.</p>\n<ul>\n<li>Make use of the idea behind  api-doc-parser to build a better cross Spec parser so that even RAML(as pointed out in <em><a href=\"https://github.com/api-platform/api-doc-parser\">hydrus#285</a></em> by <strong><a href=\"https://github.com/soderluk\">@soderluk</a></strong>) and other frameworks are supported. Add support for version 3.x of OAS(currently at Swagger 2.0).</li>\n</ul>\n<ul>\n<li>Update <em><a href=\"https://github.com/HTTP-APIs/hydra-python-core/issues/15\">hydra-python-core(#15)</a></em> as pointed out by <strong><a href=\"https://github.com/chrizandr\">@chrizandr</a></strong>, to make use of a current version of the Hydra documentation specification.</p></li>\n</ul>\n<p>All of the above will be achieved in the first phase of the project. In the second phase I’d like to implement the following:<ul>\n<li>Build a network of federated servers that implement a social media blogging platform similar in UI to Medium and having interoperability functionalities similar to that seen in the Twitter clone <strong><a href=\"https://mastadon.social/\">mastadon.social</a></strong> that allows it to be a part of a larger social media chain of servers with feeds that are cross instances and distributed in nature. This implementation utilises many features of Hydrus for the purpose of interoperability and federation of the service among the various instances that are basically hydrus based servers.</p></li>\n</ul>\n<p>Also in the second phase simple fixes and other additions I’d like to make in hydrus and its associated packages are listed below:<ul>\n<li>Add a simple <em><a href=\"https://github.com/HTTP-APIs/hydrus/issues/167\"><code>--load</code> option to the Hydrus CLI(hydrus#167)</a></em> to initialize the server with data in JSON/CSV format</li>\n</ul>\n<ul>\n<li>Add support for <em><a href=\"https://github.com/HTTP-APIs/hydrus/issues/300\">Push notifications(hydrus#300)</a></em> as suggested by <strong><a href=\"https://github.com/Mec-iS\">@Mec-iS</a></strong>. This can be achieved with HTTP/2 support, also making the flask implementation currently in use within hydrus make use of <em><a href=\"https://github.com/HTTP-APIs/hydrus/issues/372\">asyncio using quart(hydrus#372)</a></em> to call the Flask API.</li>\n</ul>\n<ul>\n<li>To build on this a network making use of a Merkle-DAG to maintain a ledger of changes to the data can also be implemented to keep track of data changes and notify each and every instance of a change. This helps client from making use of stale data.</p></li>\n</ul>\n<h2 id=\"adding-raml-and-improving-open-api-v3-support\">Adding RAML and improving Open API (v3) Support</h2><p>The <strong><a href=\"https://openapis.org\">OpenAPI Specification(OAS)</a></strong> as a documentation framework for REST APIs, allows both <em>human and computer based discovery</em> and understanding of the capabilities of a service without requiring access to its implementation or any specific human readable documentation. Hydra and OAS can be considered as sibling specifications with similar objectives, but implemented differently. OAS is quite extensive whereas hydra is lightweight. OAS has a sizable user-base, thus requiring users to port their documentation to Hydra is detrimental to the project. Similarly RAML is a documentation framework that needs to also be supported due to its.</p><p>We need to focus on improving the hydra-openapi-parser to make it full-featured, allowing users of OpenAPI, RAML or any other supported API documentation framework to experiment with and to use Hydrus in their projects, thus making the barrier to entry easier for those wanting to use it.</p><h2 id=\"improving-hydrus\">Improving Hydrus</h2><p>A manner of adding data to the Hydrus database without making <strong>PUT</strong> requests, instead using a simple <code>--load</code> option to load the data from a simple JSON/YAML/CSV<p>file is to be added to the Hydrus CLI.  Moving to quart over flask calls where possible to implement asyncio can make Hydrus better with handling load as it will move to making  use of the event loop method instead of the current sequential flow of control within Flask.</p></p>\n<p>This will also help implement HTTP/2 and make it possible to create a push notification mechanism to notify clients of changes made to data from one of the client nodes. This network must be signalled and managed from the centralized Hydrus instance that implements a checking mechanism similar to that in git servers utilising a simple Merkle DAG.</p><h2 id=\"hydrus-real-world-app\">Hydrus Real World App</h2><p>The future of the web is made with <a href=\"https://en.wikipedia.org/wiki/Distributed_social_network\">federated/distributed networks</a> instead of a centralized approach to data storage and retrieval. A new suite of apps are on the rise that make use of network of different servers that are running instances of the same kind. I propose to build a Real World App such as the one suggested in the <a href=\"https://github.com/HTTP-APIs/hydrus-real-world-app\">hydrus-real-world-app#1</a> that implements a federated clone of the Medium blogging platform.</p><p><img src=\"/assets/federated-hydrus-real-world.png\" alt=\"Federated Medium like blogging platform, Hydrus real-world\" style=\"width: 100em\"/></p><p>As is clear from the above diagram I would like to implement a distributed social media blogging platform similar to Medium. It will contain <strong>multiple instances of Hydra enabled servers</strong> that are interconnected through inter-instance communication APIs that allow for a quick and easy interconnect between the instances on the network. This is further augmented by the addition of a UI on top of hydrus based back-end that allows for the direct user interaction with service. The API can also be consumed by various other clients.</p><p>As an example, the user might be looking for a data object stored in instance C and is currently accessing the service through instance A. The service will look for the file first within itself and making use of the **Central list** find the instance C and provide the data. This can be helpful in cases where data is stored on an instance other than the current and needs to be accessed without leaving it through a hyperlink.</p><p>In a similar use case the data(eg: weather bot info) might be coming from an API that is accessing Instance B and the user might be availing this data through their own feed as a forecast. The federated network helps the user to make use of the network to make and edit the document the data(blog article) on one instance and to later access it from another where both can be just automated bots sharing documents such as scans or transcripts. The data remains human Understandable/Readable.</p><h2 id=\"schedule\">Schedule</h2><p>GSoC spans a duration of almost 4 months, with an initial community bonding period continued by 12 weeks of work on the allotted project, thus I would schedule my contributions in such a way that I can make full use of the allotted time.</p><ol><li><p>Start Implementing changes as proposed on <strong>OpenAPI</strong> parser (May 6-27, community-bonding period)</p><ul><li>Add validation and other proposed components.</li><li>Separate the functionalities into different classes/modules.</li><li>Write documentation for the parser.</li><li>Unit testing and debugging the code.</li></ul></li><li><p>Plan and finalize the implementation of RAML~>Hydra parser. (Mid May, community-bonding period)</p></li><li><p>Implement plan for a <strong>RAML~>Hydra</strong> parser.(End May-Early June)</p><ul><li>Make use of learnt concepts from Simple RAML<~Hydra parser to build a RAML~>Hydra parser.</li><li>Run tests by converting RAML sample code to HydraDoc.</li></ul></li><li><p>Integrate the <strong>RAML</strong> and  <strong>OAS</strong> parsers into a single library. (Mid June)</p><ul><li>Make necessary changes to the parser to support both OAS and RAML.<p><br /></li></p>\n</ul><p><strong>NOTE:</strong> I will be writing my Semester ending exams during the period of Early-Mid June, but would like to continue contributing. Hence balancing off the load early.</p></li><li><p>Building the example <strong>Real World App</strong> with Hydrus in a federated manner</p><ul><li>Build facility to demonstrate interactions with multiple Hydrus instances and with Dynamic API Paths (June End)</li><li>Create an interactive Medium like UI (July)</li></ul></li><li><p>Federation of instances of the <strong>Real World App</strong> (July)</p><ul><li>Multiple instances connected together through Hydra API.</li><li>API end-points(paths) providing various capabilities.<p><br /></li></p>\n</ul><p>This is the hard part that I need to learn more about how to implement.</p></li><li><p>Implement <strong>HTTP/2</strong> by porting hydrus to Quart. (Early August)</p><ul><li>Make sure everything is working as is required with Hydrus.</li><li>Add push notification as noted.</li></ul></li><li><p>Test, debug and finish pending work (if any).</p></li><li><p>Submit (August 19)</p></li></ol><h2 id=\"about-me\">About Me</h2><ul><li>I have been working on bringing various organisation at my college together to open-source their code, be it <a href=\"https://github.com/ieeemec/ieeemec/wiki\">simple websites</a> or complex apps to solve <a href=\"https://github.com/projectnalanda\">unique problems</a> they have. I have also spoken at a FOSS conference on subject matter.</li><li>I have been certified by NPTEL as a <a href=\"https://nptel.ac.in/noc/social_cert/noc17-cs28/NPTEL17CS28S1290480171005480.jpg\">Gold medallist(Elite certificate)</a>) in a Python based programming course. Otherwise I have been using Python since school while real interest has only developed lately.</li><li>Last year I worked on a Python/Django web-app called <a href=\"https://github.com/IEEEKeralaSection/rescuekerala/graphs/contributors\">rescuekerala</a>(my first real life collaborative work), which was built during the floods in Kerala, India. We didn't focus much on the APIs as we only did a single JSON data-dump. I had a real interest in working on the same due to which we built an iteration called <a href=\"http://github.com/subins2000/opensalve\">OpenSalve</a> that made use of definite end-points instead.</li><li>I would love to work on a W3C related project. My dream career involves working with IETF like organisations and that is one reason why I am an IEEE/ISOC Student Member. I am still not really a good engineer, but I would like to make use of this opportunity and am willing to continue contributing to the project, even if not selected.</li></ul><p><strong>Email</strong>: devdutt@ieee.org</p><p><strong>Telegram</strong>: @devduttshenoi</p><p><strong>GitHub</strong>: @de-sh</p><p><strong>Country</strong>: India</p><p><strong>Time Zone</strong>: GMT +5:30</p><h4 id=\"update-6-may-2019-11-45\">Update: 6 May 2019 11:45</h4><p>It was a refreshing experience to have written such a detailed proposal, sadly this project was <strong>not selected</strong> for a scholarship. I should have devoted more time and research, <em><a href=\"https://ktu.edu.in\">University</a> timings</em> also don't match well with the expectations of GSoC, so not being selected was maybe a boon in itself. I hope to participate again in the next edition with this learning experience. Meanshile I hope to develop myself technically.</p><ul><li><strong><a href=\"https://summerofcode.withgoogle.com/organizations/6557492048297984/#projects\">Selected Projects under Hydra Ecosystem</a></strong></li><li><strong><a href=\"https://summerofcode.withgoogle.com/projects/#5444359158235136\">Aswin M Prabhu's Proposal</a></strong> that was selected, he is a friend.</li></ul>"
		}
	]
}
